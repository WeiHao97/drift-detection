{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FINE_ANN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f4653fb527c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meval_bdd100k\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meval_cityscapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meval_foggy_cityscapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meval_idd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/drift-detection/eval_cityscapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mlabel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_dict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mcityscapes_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FINE_ANN\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"IMG_DIR\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#\"../cityscape_images/leftImg8bit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FINE_ANN'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "os.environ['VAL_PATH'] = '/local/rcs/wei/autonomous_navigation/data/bdd100k/images/100k/val'\n",
    "os.environ['VAL_JSON'] = '/local/rcs/wei/autonomous_navigation/data/bdd100k/labels/det_20/det_val.json'\n",
    "os.environ[\"FINE_ANN\"] = \n",
    "os.environ[\"IMG_DIR\"] = '/local/rcs/lnh2116/leftImg8bit\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2,3,4,5'\n",
    "import json\n",
    "import logging\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "from utils.torch.engine import train_one_epoch, evaluate\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "from eval_bdd100k import *\n",
    "from eval_cityscapes import *\n",
    "from eval_foggy_cityscapes import *\n",
    "from eval_idd import *\n",
    "from eval_mapillary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "##########################\n",
    "# Define global variables\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loaded trained model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate pretrained model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# label 0 is reserved for the background class\n",
    "num_classes = 9\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/faster-rcnn.pth\"))\n",
    "\n",
    "logging.info(\"loaded trained model\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(batch_size=8):\n",
    "    \"\"\"\n",
    "Get mAP scores for each object category\n",
    "\"\"\"\n",
    "    with open(val_json) as file:\n",
    "        val_labels = json.load(file)\n",
    "\n",
    "            \n",
    "    filenames = []\n",
    "    _json = []\n",
    "  \n",
    "    copy_val_labels = copy.deepcopy(val_labels)\n",
    "   \n",
    "    # get all images that contain objects\n",
    "    for idx in range(len(copy_val_labels)):\n",
    "       \n",
    "        item = copy_val_labels[idx]\n",
    "       \n",
    "        if \"labels\" not in item:\n",
    "            continue\n",
    "    \n",
    "        # if the image contains the object\n",
    "        filenames.append(item[\"name\"])\n",
    "        _json.append(item)\n",
    "           \n",
    "    assert len(filenames) == len(_json)\n",
    "        \n",
    "    dataset = bdd100k_dataset(filenames, \n",
    "                              _json, \n",
    "                              val_path)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, \n",
    "                        collate_fn=collate_fn)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = loader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "msp = []\n",
    "for images, targets in ds:\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "        images = list(img.to(device) for img in images)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        model.eval()\n",
    "        outputs = model(images)\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        msp = msp + [outputs[i]['scores'].mean().item() for i in range(batch_size)]\n",
    "        #res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_bins = 50\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# plot the cumulative histogram\n",
    "n, bins, patches = ax.hist(msp, n_bins, density=True, histtype='step',\n",
    "                           cumulative=True)\n",
    "\n",
    "# Add a line showing the expected distribution.\n",
    "# y = ...\n",
    "\n",
    "# tidy up the figure\n",
    "ax.grid(True)\n",
    "ax.legend(loc='center left')\n",
    "ax.set_title('Cumulative step histograms')\n",
    "ax.set_xlabel('MSP')\n",
    "ax.set_ylabel('Likelihood of occurrence')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'bicycle',\n",
       " 2: 'bus',\n",
       " 3: 'car',\n",
       " 4: 'motorcycle',\n",
       " 5: 'rider',\n",
       " 6: 'traffic light',\n",
       " 7: 'traffic sign',\n",
       " 8: 'truck'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {1: 'bicycle',\n",
    "\t\t\t  2: 'bus',\n",
    "\t\t\t  3: 'car',\n",
    "\t\t\t  4: 'motorcycle',\n",
    "\t\t\t  5: 'rider',\n",
    "\t\t\t  6: 'traffic light',\n",
    "\t\t\t  7: 'traffic sign',\n",
    "\t\t\t  8: 'truck'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
