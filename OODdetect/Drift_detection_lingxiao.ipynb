{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from train_model import train_model\n",
    "from test_model import test_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-flag\n"
     ]
    }
   ],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/256_ObjectCategories/'\n",
    "namelist = os.listdir(filePath)\n",
    "nameDic_cal = {}\n",
    "for name in namelist:\n",
    "    splits = name.split(\".\")\n",
    "    nameDic_cal[int(splits[0])-1] = splits[1]\n",
    "print(nameDic_cal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "fileName = '/local/rcs/ll3504/datasets/tiny-imagenet-200/words.txt'\n",
    "nameDic_tiny = {}\n",
    "with open(fileName, \"r\") as f:\n",
    "    temp = f.readlines()\n",
    "for i in range(len(temp)):\n",
    "    splits = re.split(',|\\n|\\t', temp[i])\n",
    "    nameDic_tiny[splits[0]] = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/tiny-224/train/'\n",
    "namelist = os.listdir(filePath)\n",
    "namelist.sort()\n",
    "nameDic_t = {}\n",
    "i = 0\n",
    "for name in namelist:\n",
    "    if name.startswith('n'):\n",
    "        nameDic_t[i] = name\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameDic_tiny_imageNet = {}\n",
    "for key in nameDic_t:\n",
    "    nameDic_tiny_imageNet[key] = nameDic_tiny[nameDic_t[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 goldfish', '1 centipede', '2 goose', '3 snail', '4 grasshopper', '5 cockroach', '6 backpack', '7 bathtub', '8 binoculars', '9 cannon', '10 hourglass', '11 refrigerator', '12 syringe', '13 teapot', '14 mushroom']\n"
     ]
    }
   ],
   "source": [
    "common_classes = []\n",
    "i = 0\n",
    "for key in nameDic_tiny_imageNet:\n",
    "    if nameDic_tiny_imageNet[key] in nameDic_cal.values():\n",
    "        temp = str(i)+\" \"+str(nameDic_tiny_imageNet[key])\n",
    "        common_classes.append(str(temp))\n",
    "        i += 1\n",
    "print(common_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"common_classes_tinyImageNet_Caltech256.txt\",\"w\") as f:\n",
    "    for common_class in common_classes:\n",
    "        f.write(common_class+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 goldfish\\n', '1 centipede\\n', '2 goose\\n', '3 snail\\n', '4 grasshopper\\n', '5 cockroach\\n', '6 backpack\\n', '7 bathtub\\n', '8 binoculars\\n', '9 cannon\\n', '10 hourglass\\n', '11 refrigerator\\n', '12 syringe\\n', '13 teapot\\n', '14 mushroom\\n']\n",
      "{'goldfish': 0, 'centipede': 1, 'goose': 2, 'snail': 3, 'grasshopper': 4, 'cockroach': 5, 'backpack': 6, 'bathtub': 7, 'binoculars': 8, 'cannon': 9, 'hourglass': 10, 'refrigerator': 11, 'syringe': 12, 'teapot': 13, 'mushroom': 14}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "fileName = 'common_classes_tinyImageNet_Caltech256.txt'\n",
    "common_classes = {}\n",
    "with open(fileName, \"r\") as f:\n",
    "    temp = f.readlines()\n",
    "print(temp)\n",
    "for i in range(len(temp)):\n",
    "    splits = temp[i].split()\n",
    "    common_classes[splits[1]] = int(splits[0])\n",
    "print(common_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ll3504/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 100 worker processes in total. Our suggested max number of worker in current system is 80, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/local/rcs/ll3504/datasets/tiny-224-common/'\n",
    "num_workers = {'train' : 100,'val'   : 100,'test'  : 100}\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ])\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) \n",
    "                  for x in ['train', 'val','test']}\n",
    "tiny_dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=100, shuffle=True, num_workers=num_workers[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "tiny_dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='/database', dataset_name='caltech-256-common'):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize([256, 256]),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    tr_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['train'])\n",
    "    te_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['test'])\n",
    "    print('{} train set size: {}'.format(dataset_name, len(tr_dataset)))\n",
    "    print('{} test set size: {}'.format(dataset_name, len(te_dataset)))\n",
    "\n",
    "    return tr_dataset, te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, valid_size=0.2):\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torchdata.DataLoader(train_dataset, batch_size=30, shuffle=False, num_workers=30, pin_memory=True, drop_last=True, sampler = train_sampler)\n",
    "    test_loader = torchdata.DataLoader(test_dataset, batch_size=30, shuffle=False, num_workers=30, pin_memory=True, drop_last=True, sampler = valid_sampler)\n",
    "    dataloaders = {'train': train_loader,\n",
    "                   'val': test_loader,\n",
    "                   'test': test_loader}\n",
    "    dataset_sizes ={'train': int(np.floor((1-valid_size) * num_train)),\n",
    "                    'val': int(np.floor(valid_size * num_train)),\n",
    "                    'test': int(np.floor(valid_size * num_train))}\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = '/local/rcs/ll3504/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/pascal train set size: 600\n",
      "image_CLEF/pascal test set size: 600\n"
     ]
    }
   ],
   "source": [
    "pascal_train_images, pascal_test_images = get_dataset(imagebase, 'image_CLEF/pascal')\n",
    "pascal_dataloaders, pascal_dataset_sizes = split_dataset(pascal_train_images, pascal_test_images, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/bing train set size: 600\n",
      "image_CLEF/bing test set size: 600\n"
     ]
    }
   ],
   "source": [
    "bing_train_images, bing_test_images = get_dataset(imagebase, 'image_CLEF/bing')\n",
    "bing_dataloaders, bing_dataset_sizes = split_dataset(bing_train_images, bing_test_images, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/imagenet train set size: 600\n",
      "image_CLEF/imagenet test set size: 600\n"
     ]
    }
   ],
   "source": [
    "imagenet_train_images, imagenet_test_images = get_dataset(imagebase, 'image_CLEF/imagenet')\n",
    "imagenet_dataloaders, imagenet_dataset_sizes = split_dataset(imagenet_train_images, imagenet_test_images, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/caltech train set size: 600\n",
      "image_CLEF/caltech test set size: 600\n"
     ]
    }
   ],
   "source": [
    "caltech_train_images, caltech_test_images = get_dataset(imagebase, 'image_CLEF/caltech')\n",
    "caltech_dataloaders, caltech_dataset_sizes = split_dataset(caltech_train_images, caltech_test_images, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Resnet50\n",
    "model_ft = models.resnet50(True)\n",
    "#Finetune Final few layers to adjust for tiny imagenet input\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model_ft.fc.out_features = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 27.050471305847168...Train Loss: 5.4477 Acc: 0.2833\n",
      "Val Loss: 1.5758 Acc: 0.6833\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 16.52523636817932.3..Train Loss: 0.5290 Acc: 0.8708\n",
      "Val Loss: 0.4206 Acc: 0.9000\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 5.722718238830566....Train Loss: 0.1771 Acc: 0.9562\n",
      "Val Loss: 0.3222 Acc: 0.8917\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 1.1383932828903198.3..Train Loss: 0.1088 Acc: 0.9688\n",
      "Val Loss: 0.2927 Acc: 0.9083\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 17.556192874908447.87.Train Loss: 0.0744 Acc: 0.9771\n",
      "Val Loss: 0.3076 Acc: 0.9167\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 1.0497337579727173.3..Train Loss: 0.0483 Acc: 0.9938\n",
      "Val Loss: 0.3263 Acc: 0.9250\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 10.00020146369934..4..Train Loss: 0.0360 Acc: 0.9938\n",
      "Val Loss: 0.3261 Acc: 0.9167\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 5.786183476448059.3.2.Train Loss: 0.0210 Acc: 1.0000\n",
      "Val Loss: 0.3050 Acc: 0.9250\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 14.486674070358276..4.Train Loss: 0.0410 Acc: 0.9917\n",
      "Val Loss: 0.3025 Acc: 0.9250\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Iteration: 6/6, Loss: 8.577001690864563..7..Train Loss: 0.0281 Acc: 0.9958\n",
      "Val Loss: 0.3623 Acc: 0.8833\n",
      "\n",
      "log_loss: [5.447730426987012, 0.5289986487478018, 0.17709717387333512, 0.10877417730322729, 0.07442709143894415, 0.048252541377830006, 0.03602378077145355, 0.020964380935765803, 0.04096857396264871, 0.028110530499058466]\n",
      "val_log_loss: [1.5758368968963623, 0.4205653592944145, 0.32215488453706104, 0.2927091121673584, 0.3075572857633233, 0.3263443857431412, 0.3261370547115803, 0.30496725828076404, 0.3025124765311678, 0.362306647002697]\n",
      "accuracy: [array(0.28333333), array(0.87083333), array(0.95625), array(0.96875), array(0.97708333), array(0.99375), array(0.99375), array(1.), array(0.99166667), array(0.99583333)]\n",
      "val_accuracy: [array(0.68333333), array(0.9), array(0.89166667), array(0.90833333), array(0.91666667), array(0.925), array(0.91666667), array(0.925), array(0.925), array(0.88333333)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 1m 3s\n",
      "Best Validation Accuracy: 0.9249999999999999, Epoch: 6\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train_model(\"imageclef-caltech-224\", model_ft, caltech_dataloaders, caltech_dataset_sizes, criterion, optimizer_ft, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft.load_state_dict(torch.load('./models/model_6_epoch.pt'))\n",
    "# #Test\n",
    "# test_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Resnet50-224\n",
    "model = models.resnet50()\n",
    "#Finetune Final few layers to adjust for tiny imagenet input\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model.fc.out_features = 12\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('models/imageclef-imagenet-224/model_6_epoch.pt'))\n",
    "model = model.to(device)\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4/4, Loss: 91.25153303146362..\n",
      "Test Loss: 1.7168 Acc: 0.6417\n",
      "\n",
      "Test complete in 0m 3s\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "test_model(model, pascal_dataloaders, pascal_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4/4, Loss: 1.7629026621580124.\n",
      "Test Loss: 0.1412 Acc: 0.9500\n",
      "\n",
      "Test complete in 0m 3s\n"
     ]
    }
   ],
   "source": [
    "test_model(model, imagenet_dataloaders, imagenet_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4/4, Loss: 76.30678653717041.\n",
      "Test Loss: 2.4123 Acc: 0.4667\n",
      "\n",
      "Test complete in 0m 3s\n"
     ]
    }
   ],
   "source": [
    "test_model(model, bing_dataloaders, bing_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4/4, Loss: 21.075206995010376.\n",
      "Test Loss: 0.7263 Acc: 0.7917\n",
      "\n",
      "Test complete in 0m 2s\n"
     ]
    }
   ],
   "source": [
    "test_model(model, caltech_dataloaders, caltech_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.drift_detection import drift_detection\n",
    "from utils.k_means import kmeans\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import entropy\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import chi2_contingency, ks_2samp, entropy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(model, dataloaders):\n",
    "    data = []\n",
    "    labels = []\n",
    "    uncertainties = []\n",
    "    accuracys = []\n",
    "    for x, label in dataloaders['val']:\n",
    "        x = x.cuda()\n",
    "        label = label.cuda()\n",
    "        x = model(x)\n",
    "        _, predicted = torch.max(x, 1)\n",
    "        x = x.cpu().detach().numpy()\n",
    "        uncertainty = entropy(softmax(x, axis=-1), axis=-1)\n",
    "        size = label.shape[0]\n",
    "        correct = (predicted == label).sum().item()\n",
    "        accuracy = correct/size\n",
    "        data.append(x)\n",
    "        labels.append(label)\n",
    "        uncertainties.append(uncertainty)\n",
    "        accuracys.append(accuracy)\n",
    "    return data, labels, uncertainties, accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, labels):\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for batch in data:\n",
    "        for i in batch:\n",
    "            new_data.append(i)\n",
    "    for batch in labels:\n",
    "        for i in batch:\n",
    "            new_labels.append(i)\n",
    "    return new_data, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_x, i_y, i_uncertainties, i_acc = get_result(model, imagenet_dataloaders)\n",
    "i_x_processed, i_y_processed = process_data(i_x, i_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_x, b_y, b_uncertainties, b_acc = get_result(model, bing_dataloaders)\n",
    "b_x_processed, b_y_processed = process_data(b_x, b_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x, p_y, p_uncertainties, p_acc = get_result(model, pascal_dataloaders)\n",
    "p_x_processed, p_y_processed = process_data(p_x, p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_x, c_y, c_uncertainties, c_acc = get_result(model, caltech_dataloaders)\n",
    "c_x_processed, c_y_processed = process_data(c_x, c_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = drift_detection(b_x_processed,  .05, 'KSDrift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bing: ')\n",
    "preds = detector.get_result(b_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('imagenet: ')\n",
    "preds = detector.get_result(i_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pascal: ')\n",
    "preds = detector.get_result(p_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('caltech: ')\n",
    "preds = detector.get_result(c_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(uncertainties, accuracys, labels):\n",
    "    clusters = {}\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] not in clusters:\n",
    "            clusters[labels[i]] = [i]\n",
    "        else:\n",
    "            clusters[labels[i]].append(i)\n",
    "    for cluster in clusters:\n",
    "        print(f'Cluster {cluster}: ')\n",
    "        total_acc = 0\n",
    "        total_uncertainty = 0\n",
    "        for index in clusters[cluster]:\n",
    "            total_acc += accuracys[index]\n",
    "            total_uncertainty += sum(uncertainties[index])/len(uncertainties[index])\n",
    "        avg_acc = total_acc/len(clusters[cluster])\n",
    "        avg_uncertainty = total_uncertainty/len(clusters[cluster])\n",
    "        print(f'Average accuracy: {avg_acc}')\n",
    "        print(f'Average uncertainty: {avg_uncertainty}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(total_data):\n",
    "    total_uncertainties = []\n",
    "    total_accuracies = []\n",
    "    for data in total_data:\n",
    "        uncertainty = data[0]\n",
    "        accuracy = data[1]\n",
    "        for i in range(len(uncertainty)):\n",
    "            total_uncertainties.append(uncertainty[i])\n",
    "            total_accuracies.append(accuracy[i])\n",
    "            \n",
    "    return total_uncertainties, total_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(labels, batch_size):\n",
    "    accs = []\n",
    "    for i in range(int(len(labels)/batch_size)):\n",
    "        count = {}\n",
    "        for m in range(i*batch_size, (i+1)*batch_size):\n",
    "            if labels[m] not in count:\n",
    "                count[labels[m]] = 1\n",
    "            else:\n",
    "                count[labels[m]] += 1\n",
    "        max_num = -1\n",
    "        max_label = -1\n",
    "        for co in count:\n",
    "            if count[co] > max_num:\n",
    "                max_num = count[co]\n",
    "                max_label = co\n",
    "        count = 0\n",
    "        for m in range(i*batch_size, (i+1)*batch_size):\n",
    "            if labels[m] == max_label:\n",
    "                count += 1\n",
    "        accs.append(count/batch_size)\n",
    "    return sum(accs)/len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = [[i_uncertainties, i_acc], [b_uncertainties, b_acc], [p_uncertainties, p_acc], [c_uncertainties, c_acc]]\n",
    "total_uncertainties, total_accuracies = add_data(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_uncertainties = np.array(total_uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans(total_uncertainties, 4, 500)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_acc(labels, 4)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: \n",
      "Average accuracy: 0.7333333333333334\n",
      "Average uncertainty: 0.642565000082027\n"
     ]
    }
   ],
   "source": [
    "print_result(total_uncertainties, total_accuracies, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
