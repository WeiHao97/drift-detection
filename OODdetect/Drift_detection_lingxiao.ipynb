{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from train_model import train_model\n",
    "from test_model import test_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet-tiny and Caltech-256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-flag\n"
     ]
    }
   ],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/256_ObjectCategories/'\n",
    "namelist = os.listdir(filePath)\n",
    "nameDic_cal = {}\n",
    "for name in namelist:\n",
    "    splits = name.split(\".\")\n",
    "    nameDic_cal[int(splits[0])-1] = splits[1]\n",
    "print(nameDic_cal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "fileName = '/local/rcs/ll3504/datasets/tiny-imagenet-200/words.txt'\n",
    "nameDic_tiny = {}\n",
    "with open(fileName, \"r\") as f:\n",
    "    temp = f.readlines()\n",
    "for i in range(len(temp)):\n",
    "    splits = re.split(',|\\n|\\t', temp[i])\n",
    "    nameDic_tiny[splits[0]] = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/tiny-224/train/'\n",
    "namelist = os.listdir(filePath)\n",
    "namelist.sort()\n",
    "nameDic_t = {}\n",
    "i = 0\n",
    "for name in namelist:\n",
    "    if name.startswith('n'):\n",
    "        nameDic_t[i] = name\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameDic_tiny_imageNet = {}\n",
    "for key in nameDic_t:\n",
    "    nameDic_tiny_imageNet[key] = nameDic_tiny[nameDic_t[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 goldfish', '1 centipede', '2 goose', '3 snail', '4 grasshopper', '5 cockroach', '6 backpack', '7 bathtub', '8 binoculars', '9 cannon', '10 hourglass', '11 refrigerator', '12 syringe', '13 teapot', '14 mushroom']\n"
     ]
    }
   ],
   "source": [
    "common_classes = []\n",
    "i = 0\n",
    "for key in nameDic_tiny_imageNet:\n",
    "    if nameDic_tiny_imageNet[key] in nameDic_cal.values():\n",
    "        temp = str(i)+\" \"+str(nameDic_tiny_imageNet[key])\n",
    "        common_classes.append(str(temp))\n",
    "        i += 1\n",
    "print(common_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"common_classes_tinyImageNet_Caltech256.txt\",\"w\") as f:\n",
    "    for common_class in common_classes:\n",
    "        f.write(common_class+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 goldfish\\n', '1 centipede\\n', '2 goose\\n', '3 snail\\n', '4 grasshopper\\n', '5 cockroach\\n', '6 backpack\\n', '7 bathtub\\n', '8 binoculars\\n', '9 cannon\\n', '10 hourglass\\n', '11 refrigerator\\n', '12 syringe\\n', '13 teapot\\n', '14 mushroom\\n']\n",
      "{'goldfish': 0, 'centipede': 1, 'goose': 2, 'snail': 3, 'grasshopper': 4, 'cockroach': 5, 'backpack': 6, 'bathtub': 7, 'binoculars': 8, 'cannon': 9, 'hourglass': 10, 'refrigerator': 11, 'syringe': 12, 'teapot': 13, 'mushroom': 14}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "fileName = 'common_classes_tinyImageNet_Caltech256.txt'\n",
    "common_classes = {}\n",
    "with open(fileName, \"r\") as f:\n",
    "    temp = f.readlines()\n",
    "print(temp)\n",
    "for i in range(len(temp)):\n",
    "    splits = temp[i].split()\n",
    "    common_classes[splits[1]] = int(splits[0])\n",
    "print(common_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ll3504/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 100 worker processes in total. Our suggested max number of worker in current system is 80, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/local/rcs/ll3504/datasets/tiny-224-common/'\n",
    "num_workers = {'train': 100,'val': 100,'test': 100}\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ])\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) \n",
    "                  for x in ['train', 'val','test']}\n",
    "tiny_dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=100, shuffle=True, num_workers=num_workers[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "tiny_dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageClef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='/database', dataset_name='caltech-256-common'):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize([256, 256]),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    tr_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['train'])\n",
    "    te_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['test'])\n",
    "    print('{} train set size: {}'.format(dataset_name, len(tr_dataset)))\n",
    "    print('{} test set size: {}'.format(dataset_name, len(te_dataset)))\n",
    "\n",
    "    return tr_dataset, te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, valid_size=0.2, batch_size=128):\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torchdata.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size, pin_memory=True, drop_last=True, sampler = train_sampler)\n",
    "    test_loader = torchdata.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size, pin_memory=True, drop_last=True, sampler = valid_sampler)\n",
    "    dataloaders = {'train': train_loader,\n",
    "                   'val': test_loader,\n",
    "                   'test': test_loader}\n",
    "    dataset_sizes ={'train': int(np.floor((1-valid_size) * num_train)),\n",
    "                    'val': int(np.floor(valid_size * num_train)),\n",
    "                    'test': int(np.floor(valid_size * num_train))}\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = '/local/rcs/ll3504/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/pascal train set size: 600\n",
      "image_CLEF/pascal test set size: 600\n"
     ]
    }
   ],
   "source": [
    "pascal_train_images, pascal_test_images = get_dataset(imagebase, 'image_CLEF/pascal')\n",
    "pascal_dataloaders, pascal_dataset_sizes = split_dataset(pascal_train_images, pascal_test_images, 0.2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/bing train set size: 600\n",
      "image_CLEF/bing test set size: 600\n"
     ]
    }
   ],
   "source": [
    "bing_train_images, bing_test_images = get_dataset(imagebase, 'image_CLEF/bing')\n",
    "bing_dataloaders, bing_dataset_sizes = split_dataset(bing_train_images, bing_test_images, 0.2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/imagenet train set size: 600\n",
      "image_CLEF/imagenet test set size: 600\n"
     ]
    }
   ],
   "source": [
    "imagenet_train_images, imagenet_test_images = get_dataset(imagebase, 'image_CLEF/imagenet')\n",
    "imagenet_dataloaders, imagenet_dataset_sizes = split_dataset(imagenet_train_images, imagenet_test_images, 0.2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_CLEF/caltech train set size: 600\n",
      "image_CLEF/caltech test set size: 600\n"
     ]
    }
   ],
   "source": [
    "caltech_train_images, caltech_test_images = get_dataset(imagebase, 'image_CLEF/caltech')\n",
    "caltech_dataloaders, caltech_dataset_sizes = split_dataset(caltech_train_images, caltech_test_images, 0.2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Resnet50\n",
    "model_ft = models.resnet50(True)\n",
    "#Finetune Final few layers to adjust for tiny imagenet input\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model_ft.fc.out_features = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fd62c4b6560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ll3504/anaconda3/envs/edgemonitor/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 24222, 24270, 24318, 24366, 24414, 24462, 24510, 24558, 24606, 24655, 24703, 24751, 24799, 24847, 24896, 24944, 24992, 25040, 25089, 25137, 25185, 25233, 25281, 25329, 25377, 25425, 25473, 25521, 25572, 25621, 25669, 25717, 25765, 25814, 25862, 25911, 25960, 26008, 26056) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/edgemonitor/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24174/458614858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imageclef-caltech-224\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaltech_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaltech_dataset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/edgemonitor/code/pytorch_tiny_imagenet/train_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(output_path, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs, scheduler)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 24222, 24270, 24318, 24366, 24414, 24462, 24510, 24558, 24606, 24655, 24703, 24751, 24799, 24847, 24896, 24944, 24992, 25040, 25089, 25137, 25185, 25233, 25281, 25329, 25377, 25425, 25473, 25521, 25572, 25621, 25669, 25717, 25765, 25814, 25862, 25911, 25960, 26008, 26056) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train_model(\"imageclef-caltech-224\", model_ft, caltech_dataloaders, caltech_dataset_sizes, criterion, optimizer_ft, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft.load_state_dict(torch.load('./models/model_6_epoch.pt'))\n",
    "# #Test\n",
    "# test_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22087/3997196540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Observe that all parameters are being optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Test Resnet50-224\n",
    "model_clef = models.resnet50()\n",
    "#Finetune Final few layers to adjust for tiny imagenet input\n",
    "model_clef.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model_clef.fc.out_features = 12\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_clef.load_state_dict(torch.load('models/imageclef-imagenet-224/model_6_epoch.pt'))\n",
    "model_clef = model_clef.to(device)\n",
    "\n",
    "#Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "test_model(model_clef, pascal_dataloaders, pascal_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_clef, imagenet_dataloaders, imagenet_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_clef, bing_dataloaders, bing_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_clef, caltech_dataloaders, caltech_dataset_sizes, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.drift_detection import drift_detection\n",
    "from utils.k_means import kmeans\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import entropy\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import chi2_contingency, ks_2samp, entropy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(model, dataloaders, threshold=0.0):\n",
    "    data = []\n",
    "    labels = []\n",
    "    uncertainties = []\n",
    "    accuracys = []\n",
    "    new_uncertainties = []\n",
    "    new_labels = []\n",
    "    new_predicts = []\n",
    "    for x, label in dataloaders['val']:\n",
    "        x = x.cuda()\n",
    "        label = label.cuda()\n",
    "        x = model(x)\n",
    "        _, predicted = torch.max(x, 1)\n",
    "        x = x.cpu().detach().numpy()\n",
    "        uncertainty = entropy(softmax(x, axis=-1), axis=-1)\n",
    "        uncertainty = np.array(uncertainty)\n",
    "        index = np.array(uncertainty>threshold, dtype='bool')\n",
    "        label = label.cpu().detach().numpy()\n",
    "        predicted = predicted.cpu().detach().numpy()\n",
    "        filtered_uncertainty = uncertainty[index]\n",
    "        filtered_label = label[index]\n",
    "        filtered_predicts = predicted[index]\n",
    "        new_uncertainties += list(filtered_uncertainty)\n",
    "        new_labels += list(filtered_label)\n",
    "        new_predicts += list(filtered_predicts)\n",
    "        size = label.shape[0]\n",
    "    \n",
    "    for i in range(int(len(new_uncertainties)/size)):\n",
    "        uncertainty = np.array(new_uncertainties[i*size:(i+1)*size])\n",
    "        label = np.array(new_labels[i*size:(i+1)*size])\n",
    "        predict =  np.array(new_predicts[i*size:(i+1)*size])\n",
    "        correct = (predict == label).sum().item()\n",
    "        accuracy = correct/size\n",
    "        data.append(x)\n",
    "        labels.append(label)\n",
    "        uncertainties.append(uncertainty)\n",
    "        accuracys.append(accuracy)\n",
    "    return data, labels, uncertainties, accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, labels):\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for batch in data:\n",
    "        for i in batch:\n",
    "            new_data.append(i)\n",
    "    for batch in labels:\n",
    "        for i in batch:\n",
    "            new_labels.append(i)\n",
    "    return new_data, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_x, i_y, i_uncertainties, i_acc = get_result(model_clef, imagenet_dataloaders)\n",
    "i_x_processed, i_y_processed = process_data(i_x, i_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_x, b_y, b_uncertainties, b_acc = get_result(model_clef, bing_dataloaders)\n",
    "b_x_processed, b_y_processed = process_data(b_x, b_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x, p_y, p_uncertainties, p_acc = get_result(model_clef, pascal_dataloaders)\n",
    "p_x_processed, p_y_processed = process_data(p_x, p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_x, c_y, c_uncertainties, c_acc = get_result(model_clef, caltech_dataloaders)\n",
    "c_x_processed, c_y_processed = process_data(c_x, c_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = drift_detection(b_x_processed,  .05, 'KSDrift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bing: \n",
      "Drift? No!\n",
      "Feature-wise p-values:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print('bing: ')\n",
    "preds = detector.get_result(b_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet: \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "2.54260048530509e-19\n"
     ]
    }
   ],
   "source": [
    "print('imagenet: ')\n",
    "preds = detector.get_result(i_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pascal: \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.005944146228516023\n"
     ]
    }
   ],
   "source": [
    "print('pascal: ')\n",
    "preds = detector.get_result(p_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caltech: \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0059441462285140245\n"
     ]
    }
   ],
   "source": [
    "print('caltech: ')\n",
    "preds = detector.get_result(c_x_processed)\n",
    "labels = ['No!', 'Yes!']\n",
    "flag = preds['is_drift']\n",
    "print('Drift? {}'.format(labels[flag]))\n",
    "print('Feature-wise p-values:')\n",
    "print(preds['p_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(uncertainties, accuracys, labels):\n",
    "    clusters = {}\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] not in clusters:\n",
    "            clusters[labels[i]] = [i]\n",
    "        else:\n",
    "            clusters[labels[i]].append(i)\n",
    "    for cluster in clusters:\n",
    "        print(f'Cluster {cluster}: ')\n",
    "        total_acc = 0\n",
    "        total_uncertainty = 0\n",
    "        for index in clusters[cluster]:\n",
    "            total_acc += accuracys[index]\n",
    "            total_uncertainty += sum(uncertainties[index])/len(uncertainties[index])\n",
    "        avg_acc = total_acc/len(clusters[cluster])\n",
    "        avg_uncertainty = total_uncertainty/len(clusters[cluster])\n",
    "        print(f'Average accuracy: {avg_acc}')\n",
    "        print(f'Average uncertainty: {avg_uncertainty}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(total_data):\n",
    "    total_uncertainties = []\n",
    "    total_accuracies = []\n",
    "    cluster_sizes = []\n",
    "    for data in total_data:\n",
    "        uncertainty = data[0]\n",
    "        accuracy = data[1]\n",
    "        cluster_sizes.append(len(uncertainty))\n",
    "        for i in range(len(uncertainty)):\n",
    "            total_uncertainties.append(uncertainty[i])\n",
    "            total_accuracies.append(accuracy[i])\n",
    "    return total_uncertainties, total_accuracies, cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(labels, cluster_sizes):\n",
    "    accs = []\n",
    "    pointer = 0\n",
    "    for i in range(len(cluster_sizes)):\n",
    "        count = {}\n",
    "        for m in range(pointer, pointer+cluster_sizes[i]):\n",
    "            if labels[m] not in count:\n",
    "                count[labels[m]] = 1\n",
    "            else:\n",
    "                count[labels[m]] += 1\n",
    "        max_num = -1\n",
    "        max_label = -1\n",
    "        for co in count:\n",
    "            if count[co] > max_num:\n",
    "                max_num = count[co]\n",
    "                max_label = co\n",
    "        count = 0\n",
    "        for m in range(pointer, pointer+cluster_sizes[i]):\n",
    "            if labels[m] == max_label:\n",
    "                count += 1\n",
    "        accs.append(count/cluster_sizes[i])\n",
    "        pointer = cluster_sizes[i]\n",
    "    return sum(accs)/len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = [[i_uncertainties, i_acc], [b_uncertainties, b_acc], [p_uncertainties, p_acc], [c_uncertainties, c_acc]]\n",
    "total_uncertainties, total_accuracies = merge_data(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_uncertainties = np.array(total_uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(total_uncertainties))\n",
    "print(type(total_uncertainties[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ll3504/edgemonitor/code/pytorch_tiny_imagenet/utils/k_means.py:37: RuntimeWarning: Mean of empty slice.\n",
      "  temp_cent = x[points==idx].mean(axis=0)\n",
      "/home/ll3504/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 0 0 0 0 1 1 1 1 1 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans(total_uncertainties, 4, 500)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_acc(labels, 4)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3: \n",
      "Average accuracy: 0.9047619047619048\n",
      "Average uncertainty: 0.3535600107965625\n",
      "Cluster 0: \n",
      "Average accuracy: 0.48333333333333334\n",
      "Average uncertainty: 1.0209947515264504\n",
      "Cluster 1: \n",
      "Average accuracy: 0.6266666666666667\n",
      "Average uncertainty: 0.69378399377844\n"
     ]
    }
   ],
   "source": [
    "print_result(total_uncertainties, total_accuracies, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNetC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenetc(imagebase, severity=1, batch_size=128):\n",
    "    corruption = ['zoom_blur', 'speckle_noise', 'spatter',\n",
    "                       'snow', 'glass_blur', 'motion_blur', 'saturate',\n",
    "                       'gaussian_blur', 'frost', 'fog', 'brightness', 'contrast',\n",
    "                       'elastic_transform', 'pixelate', 'jpeg_compression', 'defocus_blur']\n",
    "    corrupted_dataloaders = []\n",
    "    corrupted_dataset_sizes = []\n",
    "    imagenet_data = datasets.ImageNet(imagebase+'imagenetc/', split='val', transform=transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "                                   target_transform=None, download=False)\n",
    "    val_loader = torch.utils.data.DataLoader(imagenet_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=batch_size)\n",
    "    ref_dataloaders = { 'val': val_loader,\n",
    "                       'test': val_loader}\n",
    "    ref_dataset_sizes ={'val': int(len(val_loader.dataset)*0.02),\n",
    "                        'test': int(len(val_loader.dataset)*0.02)}\n",
    "    \n",
    "    for corr in corruption:\n",
    "        dataset_name = 'imagenetc/' + corr + '/' + str(severity)\n",
    "        corr_trian_images, corr_test_images = get_dataset(imagebase, dataset_name)\n",
    "        corr_dataloaders, corr_dataset_sizes = split_dataset(corr_trian_images, corr_test_images, 0.02, batch_size)\n",
    "        corrupted_dataloaders.append(corr_dataloaders)\n",
    "        corrupted_dataset_sizes.append(corr_dataset_sizes)\n",
    "    return ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results(model, ref_dataloaders, corrupted_dataloaders, corruption, threshold=0.0):\n",
    "    total_data = []\n",
    "    x_processed = []\n",
    "    y_processed = []\n",
    "    ref_x, ref_y, ref_uncertainty, ref_acc = get_result(model, ref_dataloaders, threshold)\n",
    "    ref_x_processed, ref_y_processed = process_data(ref_x, ref_y)\n",
    "    for i in range(len(corruption)):\n",
    "        dataloaders = corrupted_dataloaders[i]\n",
    "        x, y, uncertainty, acc = get_result(model, dataloaders, threshold)\n",
    "        x_p, y_p = process_data(x, y)\n",
    "        total_data.append([uncertainty, acc])\n",
    "        x_processed.append(x_p)\n",
    "        y_processed.append(y_p)\n",
    "        \n",
    "    total_uncertainties, total_accuracies, cluster_sizes = merge_data(total_data)\n",
    "    return ref_x_processed, ref_y_processed, total_uncertainties, total_accuracies, cluster_sizes, x_processed, y_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_drift(x_ref, x_processed, corruption, threshold, method='KSDrift'):\n",
    "    detector = drift_detection(x_ref,  threshold, method)\n",
    "    for i in range(len(corruption)):\n",
    "        print(f'Corruption type: {corruption[i]} ')\n",
    "        preds = detector.get_result(x_processed[i])\n",
    "        labels = ['No!', 'Yes!']\n",
    "        flag = preds['is_drift']\n",
    "        print('Drift? {}'.format(labels[flag]))\n",
    "        print('Feature-wise p-values:')\n",
    "        print(preds['p_val'])\n",
    "        print(\" \")\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ll3504/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ll3504/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torchvision/datasets/imagenet.py:50: RuntimeWarning: The use of the download flag is deprecated, since the dataset is no longer publicly accessible.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/ll3504/anaconda3/envs/edgemonitor/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 128 worker processes in total. Our suggested max number of worker in current system is 48, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenetc/zoom_blur/5 train set size: 50000\n",
      "imagenetc/zoom_blur/5 test set size: 50000\n",
      "imagenetc/speckle_noise/5 train set size: 50000\n",
      "imagenetc/speckle_noise/5 test set size: 50000\n",
      "imagenetc/spatter/5 train set size: 50000\n",
      "imagenetc/spatter/5 test set size: 50000\n",
      "imagenetc/snow/5 train set size: 50000\n",
      "imagenetc/snow/5 test set size: 50000\n",
      "imagenetc/glass_blur/5 train set size: 50000\n",
      "imagenetc/glass_blur/5 test set size: 50000\n",
      "imagenetc/motion_blur/5 train set size: 50000\n",
      "imagenetc/motion_blur/5 test set size: 50000\n",
      "imagenetc/saturate/5 train set size: 50000\n",
      "imagenetc/saturate/5 test set size: 50000\n",
      "imagenetc/gaussian_blur/5 train set size: 50000\n",
      "imagenetc/gaussian_blur/5 test set size: 50000\n",
      "imagenetc/frost/5 train set size: 50000\n",
      "imagenetc/frost/5 test set size: 50000\n",
      "imagenetc/fog/5 train set size: 50000\n",
      "imagenetc/fog/5 test set size: 50000\n",
      "imagenetc/brightness/5 train set size: 50000\n",
      "imagenetc/brightness/5 test set size: 50000\n",
      "imagenetc/contrast/5 train set size: 50000\n",
      "imagenetc/contrast/5 test set size: 50000\n",
      "imagenetc/elastic_transform/5 train set size: 50000\n",
      "imagenetc/elastic_transform/5 test set size: 50000\n",
      "imagenetc/pixelate/5 train set size: 50000\n",
      "imagenetc/pixelate/5 test set size: 50000\n",
      "imagenetc/jpeg_compression/5 train set size: 50000\n",
      "imagenetc/jpeg_compression/5 test set size: 50000\n",
      "imagenetc/defocus_blur/5 train set size: 50000\n",
      "imagenetc/defocus_blur/5 test set size: 50000\n"
     ]
    }
   ],
   "source": [
    "ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption = get_imagenetc(imagebase, 5, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_x_processed, ref_y_processed, total_uncertainties, total_accuracies, cluster_sizes, x_processed, y_processed = get_all_results(model, ref_dataloaders, corrupted_dataloaders, corruption, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption type: zoom_blur \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: speckle_noise \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: spatter \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "3.54354e-319\n",
      " \n",
      "Corruption type: snow \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: glass_blur \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: motion_blur \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: saturate \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "4.061571307040455e-192\n",
      " \n",
      "Corruption type: gaussian_blur \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: frost \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: fog \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: brightness \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "1.0272948668837847e-110\n",
      " \n",
      "Corruption type: contrast \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: elastic_transform \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: pixelate \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: jpeg_compression \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n",
      "Corruption type: defocus_blur \n",
      "Drift? Yes!\n",
      "Feature-wise p-values:\n",
      "0.0\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_drift': 1, 'p_val': 0.0, 'threshold': 0.05, 'distance': 0.878125}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_drift(ref_x_processed, x_processed, corruption, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_uncertainties = np.array(total_uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 96\n",
      "batch size: 128\n",
      "Size of cluster 0: 6\n",
      "Size of cluster 1: 6\n",
      "Size of cluster 2: 6\n",
      "Size of cluster 3: 6\n",
      "Size of cluster 4: 6\n",
      "Size of cluster 5: 6\n",
      "Size of cluster 6: 6\n",
      "Size of cluster 7: 6\n",
      "Size of cluster 8: 6\n",
      "Size of cluster 9: 6\n",
      "Size of cluster 10: 5\n",
      "Size of cluster 11: 7\n",
      "Size of cluster 12: 6\n",
      "Size of cluster 13: 6\n",
      "Size of cluster 14: 6\n",
      "Size of cluster 15: 6\n"
     ]
    }
   ],
   "source": [
    "print(f'data size: {total_uncertainties.shape[0]}')\n",
    "print(f'batch size: {total_uncertainties.shape[1]}')\n",
    "for i in range(len(cluster_sizes)):\n",
    "    print(f'Size of cluster {i}: {cluster_sizes[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 15 15 15 15 15 15 13 15 13 15 13  9  9  9  9  6  9 15 15  6 15 15 15\n",
      " 13 13 13 13 13 13 13 15 13 13 13 15  9  9  9  9  9  9 13 13 13 13 13 13\n",
      " 15  6 15  6  6  6  6  6  6  6  6  6  9  9  9  9  9 13 13 13 13 13 13 13\n",
      "  6  6  6 15  6  6 15 15 15 15 15 15 15  6 15 15 15  6 13 13 13 13 13 13]\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans(total_uncertainties, 16, 300)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5419642857142857\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_acc(labels, cluster_sizes)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 15: \n",
      "Average accuracy: 0.18992456896551724\n",
      "Average uncertainty: 3.200537494787192\n",
      "Cluster 13: \n",
      "Average accuracy: 0.115234375\n",
      "Average uncertainty: 4.288055385546613\n",
      "Cluster 9: \n",
      "Average accuracy: 0.39453125\n",
      "Average uncertainty: 2.0297841838837485\n",
      "Cluster 6: \n",
      "Average accuracy: 0.22121710526315788\n",
      "Average uncertainty: 2.776859505837293\n"
     ]
    }
   ],
   "source": [
    "print_result(total_uncertainties, total_accuracies, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
